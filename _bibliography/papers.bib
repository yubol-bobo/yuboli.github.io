---
---

@string{aps = {American Physical Society,}}

@article{li2025coalignment,
  abbr={Agents4Science},
  title={Co-Alignment: Rethinking Alignment as Bidirectional Human-AI Cognitive Adaptation},
  author={Li, Yubo and Song, Weiyi},
  journal={arXiv preprint arXiv:2509.12179},
  year={2025},
  url={https://openreview.net/forum?id=G5jK2OMT2q#discussion},
  doi={10.48550/arXiv.2509.12179},
  html={https://openreview.net/forum?id=G5jK2OMT2q#discussion},
  pdf={co_alignment.pdf},
  abstract={Current AI alignment through RLHF follows a single directional paradigm that AI conforms to human preferences while treating human cognition as fixed. We propose a shift to co-alignment through Bidirectional Cognitive Alignment (BiCA), where humans and AI mutually adapt. BiCA uses learnable protocols, representation mapping, and KL-budget constraints for controlled co-evolution. In collaborative navigation, BiCA achieved 85.5% success versus 70.3% baseline, with 230% better mutual adaptation and 332% better protocol convergence.}
}

@article{li2025time,
  abbr={arXiv},
  title={Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks},
  author={Li, Yubo and Krishnan, Ramayya and Padman, Rema},
  journal={arXiv preprint arXiv:2510.02712},
  year={2025},
  url={https://arxiv.org/abs/2510.02712},
  doi={10.48550/arXiv.2510.02712},
  abstract={Large Language Models (LLMs) have revolutionized conversational AI, yet their robustness in extended multi-turn dialogues remains poorly understood. Existing evaluation frameworks focus on static benchmarks and single-turn assessments, failing to capture the temporal dynamics of conversational degradation that characterize real-world interactions. In this work, we present the first comprehensive survival analysis of conversational AI robustness, analyzing 36,951 conversation turns across 9 state-of-the-art LLMs to model failure as a time-to-event process.}
}

@article{li2025chain,
  abbr={arXiv},
  title={Chain-of-Influence: Tracing Interdependencies Across Time and Features in Clinical Predictive Modelings},
  author={Li, Yubo and Padman, Rema},
  journal={arXiv preprint arXiv:2510.09895},
  year={2025},
  url={https://arxiv.org/abs/2510.09895},
  doi={10.48550/arXiv.2510.09895},
  abstract={Modeling clinical time-series data is hampered by the challenge of capturing latent, time-varying dependencies among features. State-of-the-art approaches often rely on black-box mechanisms or simple aggregation, failing to explicitly model how the influence of one clinical variable propagates through others over time. We propose Chain-of-Influence (CoI), an interpretable deep learning framework that constructs an explicit, time-unfolded graph of feature interactions.}
}

@article{li2025no,
  abbr={AMIA},
  title={No Black Box Anymore: Demystifying Clinical Predictive Modeling with Temporal-Feature Cross Attention Mechanism},
  author={Li, Yubo and Yao, Xinyu and Padman, Rema},
  journal={arXiv preprint arXiv:2503.19285},
  year={2025},
  selected={true},
  url={https://arxiv.org/abs/2503.19285}
}

@article{li2025enhancing,
  abbr={JAMIA},
  title={Enhancing End-Stage Renal Disease Outcome Prediction: A Multisourced Data-Driven Approach},
  author={Li, Yubo and Padman, Rema},
  journal={Journal of the American Medical Informatics Association},
  year={2025},
  month={Aug},
  doi={10.1093/jamia/ocaf118},
  url={https://pubmed.ncbi.nlm.nih.gov/40795063/},
  note={Online ahead of print}
}

@inproceedings{li2024towards,
  abbr={AMIA},
  title={Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques},
  author={Li, Yubo and Al-Sayouri, Saba and Padman, Rema},
  booktitle={AMIA Annual Symposium Proceedings},
  year={2024},
  month={May},
  volume={2024},
  pages={664--673},
  pmid={40417492},
  pmcid={PMC12099416},
  url={https://pmc.ncbi.nlm.nih.gov/articles/PMC12099416/},
  abstract={This study explores the potential of utilizing administrative claims data, combined with advanced machine learning and deep learning techniques, to predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major health insurance organization to develop prediction models for multiple observation windows using traditional machine learning methods such as Random Forest and XGBoost as well as deep learning approaches such as Long Short-Term Memory (LSTM) networks.}
}

@article{li2025beyond,
  abbr={arXiv},
  title={Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large Language Models},
  author={Li, Yubo and Shen, Xiaobin and Yao, Xinyu and Ding, Xueying and Miao, Yidi and Krishnan, Ramayya and Padman, Rema},
  journal={arXiv preprint arXiv:2504.04717},
  year={2025},
  doi = {10.48550/arXiv.2504.04717},
  code = {https://github.com/yubol-bobo/Awesome-Multi-Turn-LLMs},
  pdf = {beyond.pdf},
  selected={true},
  preview={beyond.png},
  abstract = {Recent advancements in large language models (LLMs) have revolutionized their ability to handle single-turn tasks, yet real-world applications demand sophisticated multi-turn interactions. This survey provides a comprehensive review of recent advancements in evaluating and enhancing multi-turn interactions in LLMs. Focusing on task-specific scenarios—from instruction following in diverse domains such as math and coding to complex conversational engagements in roleplay, healthcare, education, and even adversarial jailbreak settings—we systematically examine the challenges of maintaining context, coherence, fairness, and responsiveness over prolonged dialogues. The paper organizes current benchmarks and datasets into coherent categories that reflect the evolving landscape of multi-turn dialogue evaluation. In addition, we review a range of enhancement methodologies under multi-turn settings, including model-centric strategies (contextual learning, supervised fine-tuning, reinforcement learning, and new architectures), external integration approaches (memory-augmented, retrieval-based methods, and knowledge graph), and agent-based techniques for collaborative interactions. Finally, we discuss open challenges and propose future directions for research to further advance the robustness and effectiveness of multi-turn interactions in LLMs.}
}

@inproceedings{ACL,
    abbr={ACL},
    title = "Firm or Fickle? Evaluating Large Language Models Consistency in Sequential Interactions",
    author = "Li, Yubo  and
      Miao, Yidi  and
      Ding, Xueying  and
      Krishnan, Ramayya  and
      Padman, Rema",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2025",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = {https://aclanthology.org/2025.findings-acl.347/},
    code = {https://github.com/yubol-bobo/MT-Consistency},
    pdf = {firm_fickle.pdf},
    doi = "10.18653/v1/2025.findings-acl.347",
    preview={firm_fickle.png},
    pages = "6679--6700",
    selected={true},
    ISBN = "979-8-89176-256-5",
    abstract = "Large Language Models (LLMs) have shown remarkable capabilities across various tasks, but their deployment in high-stake domains requires consistent and coherent behavior across multiple rounds of user interaction. This paper introduces a comprehensive framework for evaluating and improving LLM response consistency, making three key contributions . First, we introduce Position-Weighted Consistency (PWC), a metric designed to capture both the importance of early-stage stability and recovery patterns in multi-turn interactions. Second, we present MT-Consistency, a carefully curated benchmark dataset spanning diverse domains and difficulty levels, specifically designed to evaluate LLM consistency under various challenging follow-up scenarios. Third, we introduce Confidence-Aware Response Generation (CARG), a framework that significantly improves response stability by explicitly integrating internal model confidence scores during the generation process. Experimental results demonstrate that CARG significantly improves response stability without sacrificing accuracy, offering a practical path toward more dependable LLM behavior in critical, real-world deployments."
}






